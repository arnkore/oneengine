/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

//! Distributed MPP operators
//! 
//! Operators designed for distributed MPP engine worker components

use std::sync::Arc;
use std::collections::HashMap;
use anyhow::Result;
use arrow::record_batch::RecordBatch;
use arrow::datatypes::SchemaRef;
use serde::{Serialize, Deserialize};
use tokio::sync::mpsc;
use uuid::Uuid;

/// Worker node identifier
pub type WorkerId = String;

/// Task identifier
pub type TaskId = Uuid;

/// Partition identifier
pub type PartitionId = u32;

/// Data exchange channel
pub type ExchangeChannel = mpsc::UnboundedSender<RecordBatch>;

/// MPP operator trait for distributed execution
pub trait MppOperator: Send + Sync {
    /// Initialize operator for distributed execution
    fn initialize(&mut self, context: &MppContext) -> Result<()>;
    
    /// Process data batch in distributed context
    fn process_batch(&mut self, batch: RecordBatch, context: &MppContext) -> Result<Vec<RecordBatch>>;
    
    /// Handle data exchange between workers
    fn exchange_data(&mut self, data: Vec<RecordBatch>, target_workers: Vec<WorkerId>) -> Result<()>;
    
    /// Handle partition-aware processing
    fn process_partition(&mut self, partition_id: PartitionId, data: RecordBatch) -> Result<RecordBatch>;
    
    /// Handle operator completion
    fn finish(&mut self, context: &MppContext) -> Result<()>;
    
    /// Get operator statistics
    fn get_stats(&self) -> MppOperatorStats;
    
    /// Handle failure recovery
    fn recover(&mut self, context: &MppContext) -> Result<()>;
}

/// MPP execution context
#[derive(Debug, Clone)]
pub struct MppContext {
    /// Current worker ID
    pub worker_id: WorkerId,
    /// Task ID
    pub task_id: TaskId,
    /// All worker IDs in the cluster
    pub worker_ids: Vec<WorkerId>,
    /// Data exchange channels
    pub exchange_channels: HashMap<WorkerId, ExchangeChannel>,
    /// Partition information
    pub partition_info: PartitionInfo,
    /// Execution configuration
    pub config: MppConfig,
}

/// Partition information
#[derive(Debug, Clone)]
pub struct PartitionInfo {
    /// Total number of partitions
    pub total_partitions: u32,
    /// Current worker's partition IDs
    pub local_partitions: Vec<PartitionId>,
    /// Partition distribution across workers
    pub partition_distribution: HashMap<PartitionId, WorkerId>,
}

/// MPP execution configuration
#[derive(Debug, Clone)]
pub struct MppConfig {
    /// Batch size for processing
    pub batch_size: usize,
    /// Memory limit per operator
    pub memory_limit: usize,
    /// Network timeout
    pub network_timeout: std::time::Duration,
    /// Retry configuration
    pub retry_config: RetryConfig,
    /// Compression enabled
    pub compression_enabled: bool,
    /// Parallelism level
    pub parallelism: usize,
}

/// Retry configuration
#[derive(Debug, Clone)]
pub struct RetryConfig {
    /// Maximum retry attempts
    pub max_attempts: u32,
    /// Initial retry delay
    pub initial_delay: std::time::Duration,
    /// Maximum retry delay
    pub max_delay: std::time::Duration,
    /// Backoff multiplier
    pub backoff_multiplier: f64,
}

/// MPP operator statistics
#[derive(Debug, Clone, Default)]
pub struct MppOperatorStats {
    /// Rows processed
    pub rows_processed: u64,
    /// Batches processed
    pub batches_processed: u64,
    /// Data exchanged (bytes)
    pub data_exchanged: u64,
    /// Network operations
    pub network_operations: u64,
    /// Processing time
    pub processing_time: std::time::Duration,
    /// Network time
    pub network_time: std::time::Duration,
    /// Retry count
    pub retry_count: u64,
    /// Error count
    pub error_count: u64,
    /// Memory usage (bytes)
    pub memory_usage: usize,
}

/// MPP operator factory
pub struct MppOperatorFactory;

impl MppOperatorFactory {
    /// Create data exchange operator
    pub fn create_data_exchange(target_workers: Vec<WorkerId>) -> Box<dyn MppOperator> {
        use crate::execution::operators::mpp_exchange::DataExchangeOperator;
        Box::new(DataExchangeOperator::new(target_workers))
    }
    
    /// Create scan operator
    pub fn create_scan(partition_id: PartitionId, table_path: String) -> Box<dyn MppOperator> {
        use crate::execution::operators::mpp_scan::{MppScanOperator, MppScanConfig, MppScanOperatorFactory};
        let config = MppScanConfig::default();
        let operator = MppScanOperatorFactory::create_iceberg_scan(
            Uuid::new_v4(),
            partition_id,
            table_path,
            config,
        ).unwrap();
        Box::new(operator)
    }
    
    /// Create hash join operator
    pub fn create_hash_join(join_condition: crate::execution::operators::mpp_join::JoinCondition) -> Box<dyn MppOperator> {
        use crate::execution::operators::mpp_join::{MppHashJoinOperator, MppJoinOperatorFactory};
        Box::new(MppJoinOperatorFactory::create_hash_join(
            Uuid::new_v4(),
            join_condition,
            1024 * 1024 * 1024, // 1GB memory limit
        ))
    }
}
