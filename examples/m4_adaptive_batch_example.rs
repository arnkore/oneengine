/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */


//! M4é‡Œç¨‹ç¢‘ï¼šè‡ªé€‚åº”æ‰¹æ¬¡å¤§å°è°ƒæ•´ç¤ºä¾‹
//! 
//! æ¼”ç¤ºæ ¹æ®ç³»ç»Ÿè´Ÿè½½ã€å†…å­˜ä½¿ç”¨æƒ…å†µå’Œå¤„ç†æ€§èƒ½åŠ¨æ€è°ƒæ•´æ‰¹æ¬¡å¤§å°

use oneengine::execution::operators::adaptive_batch::{AdaptiveBatchAdjuster, AdaptiveBatchConfig, PerformanceTrend};
use arrow::record_batch::RecordBatch;
use arrow::array::{Int32Array, StringArray, Float64Array};
use arrow::datatypes::{Schema, Field, DataType};
use std::sync::Arc;
use std::time::{Instant, Duration};
use std::thread;

/// åˆ›å»ºæµ‹è¯•æ•°æ®
fn create_test_batch(size: usize) -> RecordBatch {
    let id_data = Int32Array::from((0..size).map(|i| i as i32).collect::<Vec<i32>>());
    let name_data = StringArray::from(
        (0..size).map(|i| format!("Name_{}", i)).collect::<Vec<String>>()
    );
    let salary_data = Float64Array::from(
        (0..size).map(|i| 50000.0 + (i as f64 * 1000.0)).collect::<Vec<f64>>()
    );
    
    let schema = Schema::new(vec![
        Field::new("id", DataType::Int32, false),
        Field::new("name", DataType::Utf8, false),
        Field::new("salary", DataType::Float64, false),
    ]);
    
    RecordBatch::try_new(
        Arc::new(schema),
        vec![
            Arc::new(id_data),
            Arc::new(name_data),
            Arc::new(salary_data),
        ],
    ).unwrap()
}

/// æ¨¡æ‹Ÿæ•°æ®å¤„ç†
fn process_batch(batch: &RecordBatch, complexity: f64) -> Duration {
    let start = Instant::now();
    
    // æ¨¡æ‹Ÿä¸åŒå¤æ‚åº¦çš„å¤„ç†
    let sleep_duration = Duration::from_micros((batch.num_rows() as f64 * complexity) as u64);
    thread::sleep(sleep_duration);
    
    start.elapsed()
}

/// æ¨¡æ‹Ÿå†…å­˜ä½¿ç”¨
fn calculate_memory_usage(batch: &RecordBatch, memory_factor: f64) -> usize {
    let base_memory = batch.get_array_memory_size();
    (base_memory as f64 * memory_factor) as usize
}

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸš€ M4é‡Œç¨‹ç¢‘ï¼šè‡ªé€‚åº”æ‰¹æ¬¡å¤§å°è°ƒæ•´æ¼”ç¤º");
    println!("================================================");
    
    // åˆ›å»ºè‡ªé€‚åº”æ‰¹æ¬¡é…ç½®
    let config = AdaptiveBatchConfig {
        initial_batch_size: 1000,
        min_batch_size: 100,
        max_batch_size: 10000,
        adjustment_step: 500,
        stats_window_size: 20,
        target_throughput: 50000.0, // 5ä¸‡è¡Œ/ç§’
        target_memory_usage: 10 * 1024 * 1024, // 10MB
        adjustment_interval_ms: 500, // 500ms
        performance_threshold: 0.8,
        memory_threshold: 1.2,
    };
    
    println!("ğŸ“Š è‡ªé€‚åº”æ‰¹æ¬¡é…ç½®ï¼š");
    println!("âœ… åˆå§‹æ‰¹æ¬¡å¤§å°: {}", config.initial_batch_size);
    println!("âœ… æœ€å°æ‰¹æ¬¡å¤§å°: {}", config.min_batch_size);
    println!("âœ… æœ€å¤§æ‰¹æ¬¡å¤§å°: {}", config.max_batch_size);
    println!("âœ… è°ƒæ•´æ­¥é•¿: {}", config.adjustment_step);
    println!("âœ… ç›®æ ‡ååé‡: {:.0} è¡Œ/ç§’", config.target_throughput);
    println!("âœ… ç›®æ ‡å†…å­˜ä½¿ç”¨: {} MB", config.target_memory_usage / 1024 / 1024);
    println!();
    
    // åˆ›å»ºè‡ªé€‚åº”æ‰¹æ¬¡è°ƒæ•´å™¨
    let adjuster = AdaptiveBatchAdjuster::new(config);
    
    // æµ‹è¯•åœºæ™¯1ï¼šæ­£å¸¸è´Ÿè½½
    println!("ğŸ”„ æµ‹è¯•åœºæ™¯1ï¼šæ­£å¸¸è´Ÿè½½");
    test_normal_load(&adjuster).await?;
    println!();
    
    // æµ‹è¯•åœºæ™¯2ï¼šé«˜è´Ÿè½½
    println!("ğŸ”„ æµ‹è¯•åœºæ™¯2ï¼šé«˜è´Ÿè½½");
    test_high_load(&adjuster).await?;
    println!();
    
    // æµ‹è¯•åœºæ™¯3ï¼šå†…å­˜å—é™
    println!("ğŸ”„ æµ‹è¯•åœºæ™¯3ï¼šå†…å­˜å—é™");
    test_memory_constrained(&adjuster).await?;
    println!();
    
    // æµ‹è¯•åœºæ™¯4ï¼šæ€§èƒ½ä¼˜åŒ–
    println!("ğŸ”„ æµ‹è¯•åœºæ™¯4ï¼šæ€§èƒ½ä¼˜åŒ–");
    test_performance_optimization(&adjuster).await?;
    println!();
    
    // æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
    println!("ğŸ“ˆ æœ€ç»ˆæ€§èƒ½ç»Ÿè®¡ï¼š");
    let summary = adjuster.get_performance_summary();
    println!("âœ… æœ€ç»ˆæ‰¹æ¬¡å¤§å°: {}", summary.current_batch_size);
    println!("âœ… æ€»å¤„ç†è¡Œæ•°: {}", summary.total_rows_processed);
    println!("âœ… æ•´ä½“ååé‡: {:.2} è¡Œ/ç§’", summary.overall_throughput);
    println!("âœ… å½“å‰å†…å­˜ä½¿ç”¨: {} MB", summary.current_memory_usage / 1024 / 1024);
    println!("âœ… æ€§èƒ½è¶‹åŠ¿: {:?}", summary.performance_trend);
    println!("âœ… ç»Ÿè®¡æ ·æœ¬æ•°: {}", summary.stats_count);
    
    println!();
    println!("ğŸ¯ M4é‡Œç¨‹ç¢‘å®Œæˆï¼");
    println!("âœ… è‡ªé€‚åº”æ‰¹æ¬¡å¤§å°è°ƒæ•´å·²å®ç°");
    println!("âœ… æ”¯æŒåŸºäºæ€§èƒ½çš„åŠ¨æ€è°ƒæ•´");
    println!("âœ… æ”¯æŒåŸºäºå†…å­˜ä½¿ç”¨çš„è°ƒæ•´");
    println!("âœ… æ”¯æŒæ€§èƒ½è¶‹åŠ¿åˆ†æ");
    println!("âœ… æ”¯æŒå¤šåœºæ™¯è‡ªé€‚åº”ä¼˜åŒ–");
    println!("âœ… æ”¯æŒå®æ—¶ç»Ÿè®¡å’Œç›‘æ§");
    
    Ok(())
}

async fn test_normal_load(adjuster: &AdaptiveBatchAdjuster) -> Result<(), Box<dyn std::error::Error>> {
    let start = Instant::now();
    let mut total_rows = 0;
    
    for i in 0..10 {
        let batch_size = adjuster.get_current_batch_size();
        let batch = create_test_batch(batch_size);
        
        // æ¨¡æ‹Ÿæ­£å¸¸å¤„ç†ï¼ˆå¤æ‚åº¦1.0ï¼‰
        let processing_time = process_batch(&batch, 1.0);
        let memory_usage = calculate_memory_usage(&batch, 1.0);
        
        // è®°å½•ç»Ÿè®¡
        adjuster.record_batch_stats(batch_size, processing_time, memory_usage);
        total_rows += batch_size;
        
        // å°è¯•è°ƒæ•´æ‰¹æ¬¡å¤§å°
        if let Some(new_size) = adjuster.adjust_batch_size() {
            println!("  ğŸ“Š æ‰¹æ¬¡å¤§å°è°ƒæ•´: {} -> {} (ç¬¬{}è½®)", 
                     batch_size, new_size, i + 1);
        }
        
        // æ˜¾ç¤ºæ€§èƒ½ç»Ÿè®¡
        let summary = adjuster.get_performance_summary();
        println!("  ğŸ“ˆ ç¬¬{}è½®: æ‰¹æ¬¡å¤§å°={}, ååé‡={:.0} è¡Œ/ç§’, å†…å­˜={} MB", 
                 i + 1, batch_size, summary.overall_throughput, 
                 memory_usage / 1024 / 1024);
        
        // æ¨¡æ‹Ÿå¤„ç†é—´éš”
        tokio::time::sleep(Duration::from_millis(100)).await;
    }
    
    let duration = start.elapsed();
    println!("âœ… æ­£å¸¸è´Ÿè½½æµ‹è¯•å®Œæˆ: {} è¡Œ, {:.2} ç§’", total_rows, duration.as_secs_f64());
    
    Ok(())
}

async fn test_high_load(adjuster: &AdaptiveBatchAdjuster) -> Result<(), Box<dyn std::error::Error>> {
    let start = Instant::now();
    let mut total_rows = 0;
    
    for i in 0..8 {
        let batch_size = adjuster.get_current_batch_size();
        let batch = create_test_batch(batch_size);
        
        // æ¨¡æ‹Ÿé«˜è´Ÿè½½å¤„ç†ï¼ˆå¤æ‚åº¦2.0ï¼‰
        let processing_time = process_batch(&batch, 2.0);
        let memory_usage = calculate_memory_usage(&batch, 1.2);
        
        // è®°å½•ç»Ÿè®¡
        adjuster.record_batch_stats(batch_size, processing_time, memory_usage);
        total_rows += batch_size;
        
        // å°è¯•è°ƒæ•´æ‰¹æ¬¡å¤§å°
        if let Some(new_size) = adjuster.adjust_batch_size() {
            println!("  ğŸ“Š æ‰¹æ¬¡å¤§å°è°ƒæ•´: {} -> {} (ç¬¬{}è½®)", 
                     batch_size, new_size, i + 1);
        }
        
        // æ˜¾ç¤ºæ€§èƒ½ç»Ÿè®¡
        let summary = adjuster.get_performance_summary();
        println!("  ğŸ“ˆ ç¬¬{}è½®: æ‰¹æ¬¡å¤§å°={}, ååé‡={:.0} è¡Œ/ç§’, å†…å­˜={} MB", 
                 i + 1, batch_size, summary.overall_throughput, 
                 memory_usage / 1024 / 1024);
        
        // æ¨¡æ‹Ÿå¤„ç†é—´éš”
        tokio::time::sleep(Duration::from_millis(150)).await;
    }
    
    let duration = start.elapsed();
    println!("âœ… é«˜è´Ÿè½½æµ‹è¯•å®Œæˆ: {} è¡Œ, {:.2} ç§’", total_rows, duration.as_secs_f64());
    
    Ok(())
}

async fn test_memory_constrained(adjuster: &AdaptiveBatchAdjuster) -> Result<(), Box<dyn std::error::Error>> {
    let start = Instant::now();
    let mut total_rows = 0;
    
    for i in 0..6 {
        let batch_size = adjuster.get_current_batch_size();
        let batch = create_test_batch(batch_size);
        
        // æ¨¡æ‹Ÿå†…å­˜å—é™å¤„ç†ï¼ˆå†…å­˜å› å­1.5ï¼‰
        let processing_time = process_batch(&batch, 1.2);
        let memory_usage = calculate_memory_usage(&batch, 1.5);
        
        // è®°å½•ç»Ÿè®¡
        adjuster.record_batch_stats(batch_size, processing_time, memory_usage);
        total_rows += batch_size;
        
        // å°è¯•è°ƒæ•´æ‰¹æ¬¡å¤§å°
        if let Some(new_size) = adjuster.adjust_batch_size() {
            println!("  ğŸ“Š æ‰¹æ¬¡å¤§å°è°ƒæ•´: {} -> {} (ç¬¬{}è½®)", 
                     batch_size, new_size, i + 1);
        }
        
        // æ˜¾ç¤ºæ€§èƒ½ç»Ÿè®¡
        let summary = adjuster.get_performance_summary();
        println!("  ğŸ“ˆ ç¬¬{}è½®: æ‰¹æ¬¡å¤§å°={}, ååé‡={:.0} è¡Œ/ç§’, å†…å­˜={} MB", 
                 i + 1, batch_size, summary.overall_throughput, 
                 memory_usage / 1024 / 1024);
        
        // æ¨¡æ‹Ÿå¤„ç†é—´éš”
        tokio::time::sleep(Duration::from_millis(200)).await;
    }
    
    let duration = start.elapsed();
    println!("âœ… å†…å­˜å—é™æµ‹è¯•å®Œæˆ: {} è¡Œ, {:.2} ç§’", total_rows, duration.as_secs_f64());
    
    Ok(())
}

async fn test_performance_optimization(adjuster: &AdaptiveBatchAdjuster) -> Result<(), Box<dyn std::error::Error>> {
    let start = Instant::now();
    let mut total_rows = 0;
    
    for i in 0..12 {
        let batch_size = adjuster.get_current_batch_size();
        let batch = create_test_batch(batch_size);
        
        // æ¨¡æ‹Ÿæ€§èƒ½ä¼˜åŒ–å¤„ç†ï¼ˆå¤æ‚åº¦0.8ï¼‰
        let processing_time = process_batch(&batch, 0.8);
        let memory_usage = calculate_memory_usage(&batch, 0.9);
        
        // è®°å½•ç»Ÿè®¡
        adjuster.record_batch_stats(batch_size, processing_time, memory_usage);
        total_rows += batch_size;
        
        // å°è¯•è°ƒæ•´æ‰¹æ¬¡å¤§å°
        if let Some(new_size) = adjuster.adjust_batch_size() {
            println!("  ğŸ“Š æ‰¹æ¬¡å¤§å°è°ƒæ•´: {} -> {} (ç¬¬{}è½®)", 
                     batch_size, new_size, i + 1);
        }
        
        // æ˜¾ç¤ºæ€§èƒ½ç»Ÿè®¡
        let summary = adjuster.get_performance_summary();
        println!("  ğŸ“ˆ ç¬¬{}è½®: æ‰¹æ¬¡å¤§å°={}, ååé‡={:.0} è¡Œ/ç§’, å†…å­˜={} MB", 
                 i + 1, batch_size, summary.overall_throughput, 
                 memory_usage / 1024 / 1024);
        
        // æ¨¡æ‹Ÿå¤„ç†é—´éš”
        tokio::time::sleep(Duration::from_millis(80)).await;
    }
    
    let duration = start.elapsed();
    println!("âœ… æ€§èƒ½ä¼˜åŒ–æµ‹è¯•å®Œæˆ: {} è¡Œ, {:.2} ç§’", total_rows, duration.as_secs_f64());
    
    Ok(())
}
