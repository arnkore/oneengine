/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

//! ç»Ÿä¸€æ¹–ä»“è¯»å–å™¨ç¤ºä¾‹
//! 
//! æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ç»Ÿä¸€æ¹–ä»“è¯»å–å™¨æ”¯æŒå¤šç§æ¹–ä»“æ ¼å¼ï¼ˆIcebergã€Paimonã€Hudiç­‰ï¼‰

use oneengine::datalake::unified_lake_reader::*;
use std::collections::HashMap;

fn main() -> Result<(), Box<dyn std::error::Error>> {
    // åˆå§‹åŒ–æ—¥å¿—
    tracing_subscriber::fmt::init();
    
    println!("ğŸš€ ç»Ÿä¸€æ¹–ä»“è¯»å–å™¨ç¤ºä¾‹");
    println!("================================================");
    
    // ç¤ºä¾‹1ï¼šIcebergè¡¨è¯»å–
    println!("ğŸ”„ ç¤ºä¾‹1ï¼šIcebergè¡¨è¯»å–");
    println!("------------------------");
    test_iceberg_reading()?;
    println!();
    
    // ç¤ºä¾‹2ï¼šPaimonè¡¨è¯»å–
    println!("ğŸ”„ ç¤ºä¾‹2ï¼šPaimonè¡¨è¯»å–");
    println!("------------------------");
    test_paimon_reading()?;
    println!();
    
    // ç¤ºä¾‹3ï¼šHudiè¡¨è¯»å–
    println!("ğŸ”„ ç¤ºä¾‹3ï¼šHudiè¡¨è¯»å–");
    println!("------------------------");
    test_hudi_reading()?;
    println!();
    
    // ç¤ºä¾‹4ï¼šParquetæ–‡ä»¶è¯»å–
    println!("ğŸ”„ ç¤ºä¾‹4ï¼šParquetæ–‡ä»¶è¯»å–");
    println!("------------------------");
    test_parquet_reading()?;
    println!();
    
    // ç¤ºä¾‹5ï¼šORCæ–‡ä»¶è¯»å–
    println!("ğŸ”„ ç¤ºä¾‹5ï¼šORCæ–‡ä»¶è¯»å–");
    println!("------------------------");
    test_orc_reading()?;
    println!();
    
    println!("ğŸ¯ ç»Ÿä¸€æ¹–ä»“è¯»å–å™¨ç¤ºä¾‹å®Œæˆï¼");
    println!("âœ… æ”¯æŒå¤šç§æ¹–ä»“æ ¼å¼ï¼šIcebergã€Paimonã€Hudiã€Parquetã€ORC");
    println!("âœ… æä¾›ç»Ÿä¸€çš„APIæ¥å£å’Œé…ç½®");
    println!("âœ… æ”¯æŒè°“è¯ä¸‹æ¨ã€åˆ—æŠ•å½±ã€åˆ†åŒºå‰ªæç­‰ä¼˜åŒ–");
    println!("âœ… æ”¯æŒæ—¶é—´æ—…è¡Œå’Œå¢é‡è¯»å–ï¼ˆé€‚ç”¨äºæ”¯æŒçš„æ ¼å¼ï¼‰");
    println!("âœ… ä¸ºæœªæ¥æ‰©å±•æ›´å¤šæ¹–ä»“æ ¼å¼æä¾›äº†è‰¯å¥½çš„æ¶æ„åŸºç¡€");
    
    Ok(())
}

/// æµ‹è¯•Icebergè¡¨è¯»å–
fn test_iceberg_reading() -> Result<(), Box<dyn std::error::Error>> {
    let config = UnifiedLakeReaderConfig {
        format: LakeFormat::Iceberg,
        table_path: "s3://warehouse/sample_iceberg_table".to_string(),
        warehouse_path: Some("s3://warehouse".to_string()),
        predicates: vec![
            UnifiedPredicate::Equal { 
                column: "year".to_string(), 
                value: "2023".to_string() 
            },
            UnifiedPredicate::GreaterThan { 
                column: "amount".to_string(), 
                value: "1000".to_string() 
            },
        ],
        column_projection: Some(ColumnProjection {
            columns: vec!["id".to_string(), "name".to_string(), "amount".to_string()],
            select_all: false,
        }),
        time_travel: Some(TimeTravelConfig {
            snapshot_id: Some(12345),
            timestamp_ms: None,
            branch: None,
            tag: None,
        }),
        partition_pruning: Some(PartitionPruningInfo {
            partition_columns: vec!["year".to_string(), "month".to_string()],
            partition_values: HashMap::from([
                ("year".to_string(), "2023".to_string()),
                ("month".to_string(), "12".to_string()),
            ]),
            matches: true,
        }),
        enable_predicate_pushdown: true,
        enable_column_projection: true,
        enable_partition_pruning: true,
        enable_time_travel: true,
        enable_incremental_read: false,
        batch_size: 8192,
        max_concurrent_reads: 4,
        incremental_read: None,
    };
    
    let mut reader = UnifiedLakeReader::new(config);
    
    // æ‰“å¼€è¡¨
    reader.open()?;
    println!("âœ… Icebergè¡¨æ‰“å¼€æˆåŠŸ");
    
    // è·å–å…ƒæ•°æ®
    let metadata = reader.get_metadata()?;
    println!("  ğŸ“ˆ è¡¨ID: {}", metadata.table_id);
    println!("  ğŸ“ˆ è¡¨å: {}", metadata.table_name);
    println!("  ğŸ“ˆ å‘½åç©ºé—´: {}", metadata.namespace);
    println!("  ğŸ“ˆ å½“å‰å¿«ç…§ID: {:?}", metadata.current_snapshot_id);
    
    // è·å–ç»Ÿè®¡ä¿¡æ¯
    let stats = reader.get_statistics()?;
    println!("  ğŸ“ˆ æ€»æ–‡ä»¶æ•°: {}", stats.total_files);
    println!("  ğŸ“ˆ æ€»è®°å½•æ•°: {}", stats.total_records);
    println!("  ğŸ“ˆ æ€»æ–‡ä»¶å¤§å°: {} bytes", stats.total_size_bytes);
    
    // åº”ç”¨ä¼˜åŒ–
    let filtered_files = reader.apply_predicate_pushdown()?;
    println!("  ğŸ“ˆ è°“è¯ä¸‹æ¨è¿‡æ»¤æ–‡ä»¶æ•°: {}", filtered_files);
    
    reader.apply_column_projection()?;
    println!("  ğŸ“ˆ åˆ—æŠ•å½±åº”ç”¨æˆåŠŸ");
    
    let pruned_files = reader.apply_partition_pruning()?;
    println!("  ğŸ“ˆ åˆ†åŒºå‰ªæè¿‡æ»¤æ–‡ä»¶æ•°: {}", pruned_files);
    
    reader.apply_time_travel()?;
    println!("  ğŸ“ˆ æ—¶é—´æ—…è¡Œåº”ç”¨æˆåŠŸ");
    
    // è¯»å–æ•°æ®
    let batches = reader.read_data()?;
    println!("  ğŸ“ˆ è¯»å–åˆ° {} ä¸ªæ‰¹æ¬¡", batches.len());
    
    Ok(())
}

/// æµ‹è¯•Paimonè¡¨è¯»å–
fn test_paimon_reading() -> Result<(), Box<dyn std::error::Error>> {
    let config = UnifiedLakeReaderConfig {
        format: LakeFormat::Paimon,
        table_path: "s3://warehouse/sample_paimon_table".to_string(),
        warehouse_path: Some("s3://warehouse".to_string()),
        predicates: vec![
            UnifiedPredicate::Equal { 
                column: "status".to_string(), 
                value: "active".to_string() 
            },
        ],
        column_projection: Some(ColumnProjection {
            columns: vec!["id".to_string(), "name".to_string(), "value".to_string()],
            select_all: false,
        }),
        enable_predicate_pushdown: true,
        enable_column_projection: true,
        enable_partition_pruning: true,
        enable_time_travel: false,
        enable_incremental_read: true,
        batch_size: 4096,
        max_concurrent_reads: 2,
        time_travel: None,
        partition_pruning: None,
        incremental_read: Some(IncrementalReadConfig {
            start_snapshot_id: Some(100),
            end_snapshot_id: Some(200),
            start_timestamp_ms: None,
            end_timestamp_ms: None,
        }),
    };
    
    let mut reader = UnifiedLakeReader::new(config);
    
    // æ‰“å¼€è¡¨
    reader.open()?;
    println!("âœ… Paimonè¡¨æ‰“å¼€æˆåŠŸ");
    
    // è·å–å…ƒæ•°æ®
    let metadata = reader.get_metadata()?;
    println!("  ğŸ“ˆ è¡¨ID: {}", metadata.table_id);
    println!("  ğŸ“ˆ è¡¨å: {}", metadata.table_name);
    
    // åº”ç”¨å¢é‡è¯»å–
    reader.apply_incremental_read()?;
    println!("  ğŸ“ˆ å¢é‡è¯»å–åº”ç”¨æˆåŠŸ");
    
    // è¯»å–æ•°æ®
    let batches = reader.read_data()?;
    println!("  ğŸ“ˆ è¯»å–åˆ° {} ä¸ªæ‰¹æ¬¡", batches.len());
    
    Ok(())
}

/// æµ‹è¯•Hudiè¡¨è¯»å–
fn test_hudi_reading() -> Result<(), Box<dyn std::error::Error>> {
    let config = UnifiedLakeReaderConfig {
        format: LakeFormat::Hudi,
        table_path: "s3://warehouse/sample_hudi_table".to_string(),
        warehouse_path: Some("s3://warehouse".to_string()),
        predicates: vec![
            UnifiedPredicate::GreaterThan { 
                column: "timestamp".to_string(), 
                value: "2023-01-01".to_string() 
            },
        ],
        column_projection: Some(ColumnProjection {
            columns: vec!["id".to_string(), "name".to_string(), "timestamp".to_string()],
            select_all: false,
        }),
        enable_predicate_pushdown: true,
        enable_column_projection: true,
        enable_partition_pruning: true,
        enable_time_travel: false,
        enable_incremental_read: true,
        batch_size: 1024,
        max_concurrent_reads: 1,
        time_travel: None,
        partition_pruning: None,
        incremental_read: Some(IncrementalReadConfig {
            start_timestamp_ms: Some(1672531200000), // 2023-01-01
            end_timestamp_ms: Some(1704067200000),   // 2024-01-01
            start_snapshot_id: None,
            end_snapshot_id: None,
        }),
    };
    
    let mut reader = UnifiedLakeReader::new(config);
    
    // æ‰“å¼€è¡¨
    reader.open()?;
    println!("âœ… Hudiè¡¨æ‰“å¼€æˆåŠŸ");
    
    // è·å–å…ƒæ•°æ®
    let metadata = reader.get_metadata()?;
    println!("  ğŸ“ˆ è¡¨ID: {}", metadata.table_id);
    println!("  ğŸ“ˆ è¡¨å: {}", metadata.table_name);
    
    // åº”ç”¨å¢é‡è¯»å–
    reader.apply_incremental_read()?;
    println!("  ğŸ“ˆ å¢é‡è¯»å–åº”ç”¨æˆåŠŸ");
    
    // è¯»å–æ•°æ®
    let batches = reader.read_data()?;
    println!("  ğŸ“ˆ è¯»å–åˆ° {} ä¸ªæ‰¹æ¬¡", batches.len());
    
    Ok(())
}

/// æµ‹è¯•Parquetæ–‡ä»¶è¯»å–
fn test_parquet_reading() -> Result<(), Box<dyn std::error::Error>> {
    let config = UnifiedLakeReaderConfig {
        format: LakeFormat::Parquet,
        table_path: "data/sample.parquet".to_string(),
        warehouse_path: None,
        predicates: vec![
            UnifiedPredicate::Equal { 
                column: "category".to_string(), 
                value: "electronics".to_string() 
            },
        ],
        column_projection: Some(ColumnProjection {
            columns: vec!["id".to_string(), "name".to_string(), "price".to_string()],
            select_all: false,
        }),
        enable_predicate_pushdown: true,
        enable_column_projection: true,
        enable_partition_pruning: false,
        enable_time_travel: false,
        enable_incremental_read: false,
        batch_size: 2048,
        max_concurrent_reads: 1,
        time_travel: None,
        partition_pruning: None,
        incremental_read: None,
    };
    
    let mut reader = UnifiedLakeReader::new(config);
    
    // æ‰“å¼€æ–‡ä»¶
    reader.open()?;
    println!("âœ… Parquetæ–‡ä»¶æ‰“å¼€æˆåŠŸ");
    
    // è·å–å…ƒæ•°æ®
    let metadata = reader.get_metadata()?;
    println!("  ğŸ“ˆ è¡¨ID: {}", metadata.table_id);
    println!("  ğŸ“ˆ è¡¨å: {}", metadata.table_name);
    
    // åº”ç”¨ä¼˜åŒ–
    let filtered_files = reader.apply_predicate_pushdown()?;
    println!("  ğŸ“ˆ è°“è¯ä¸‹æ¨è¿‡æ»¤æ–‡ä»¶æ•°: {}", filtered_files);
    
    reader.apply_column_projection()?;
    println!("  ğŸ“ˆ åˆ—æŠ•å½±åº”ç”¨æˆåŠŸ");
    
    // è¯»å–æ•°æ®
    let batches = reader.read_data()?;
    println!("  ğŸ“ˆ è¯»å–åˆ° {} ä¸ªæ‰¹æ¬¡", batches.len());
    
    Ok(())
}

/// æµ‹è¯•ORCæ–‡ä»¶è¯»å–
fn test_orc_reading() -> Result<(), Box<dyn std::error::Error>> {
    let config = UnifiedLakeReaderConfig {
        format: LakeFormat::Orc,
        table_path: "data/sample.orc".to_string(),
        warehouse_path: None,
        predicates: vec![
            UnifiedPredicate::Range { 
                column: "age".to_string(), 
                min: "18".to_string(), 
                max: "65".to_string() 
            },
        ],
        column_projection: Some(ColumnProjection {
            columns: vec!["id".to_string(), "name".to_string(), "age".to_string()],
            select_all: false,
        }),
        enable_predicate_pushdown: true,
        enable_column_projection: true,
        enable_partition_pruning: false,
        enable_time_travel: false,
        enable_incremental_read: false,
        batch_size: 1024,
        max_concurrent_reads: 1,
        time_travel: None,
        partition_pruning: None,
        incremental_read: None,
    };
    
    let mut reader = UnifiedLakeReader::new(config);
    
    // æ‰“å¼€æ–‡ä»¶
    reader.open()?;
    println!("âœ… ORCæ–‡ä»¶æ‰“å¼€æˆåŠŸ");
    
    // è·å–å…ƒæ•°æ®
    let metadata = reader.get_metadata()?;
    println!("  ğŸ“ˆ è¡¨ID: {}", metadata.table_id);
    println!("  ğŸ“ˆ è¡¨å: {}", metadata.table_name);
    
    // åº”ç”¨ä¼˜åŒ–
    let filtered_files = reader.apply_predicate_pushdown()?;
    println!("  ğŸ“ˆ è°“è¯ä¸‹æ¨è¿‡æ»¤æ–‡ä»¶æ•°: {}", filtered_files);
    
    reader.apply_column_projection()?;
    println!("  ğŸ“ˆ åˆ—æŠ•å½±åº”ç”¨æˆåŠŸ");
    
    // è¯»å–æ•°æ®
    let batches = reader.read_data()?;
    println!("  ğŸ“ˆ è¯»å–åˆ° {} ä¸ªæ‰¹æ¬¡", batches.len());
    
    Ok(())
}
