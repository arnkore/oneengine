/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */


//! å…¨é¢ç³»ç»Ÿé›†æˆæµ‹è¯•
//! 
//! éªŒè¯æ•´ä¸ªOneEngineç³»ç»Ÿçš„å®Œæ•´æ‰“é€šï¼š
//! Taskè°ƒåº¦ â†’ Driverè°ƒåº¦ â†’ Pipelineæ‰§è¡Œ â†’ Pipelineè°ƒåº¦æ¡†æž¶ â†’ Operatorç®—å­ â†’ æ¹–ä»“åˆ—å¼å†…å®¹è¯»å–
//! 
//! æ¯ä¸ªçŽ¯èŠ‚éƒ½æ˜¯ç”Ÿäº§çº§åˆ«çš„å®Œæ•´å®žçŽ°ï¼Œæ— ä»»ä½•ç®€åŒ–ä»£ç 

use oneengine::core::engine::OneEngine;
use oneengine::core::task::{Task, TaskType, Priority, ResourceRequirements};
use oneengine::core::pipeline::{Pipeline, PipelineEdge, EdgeType};
use oneengine::utils::config::Config;
use arrow::array::*;
use arrow::datatypes::*;
use arrow::record_batch::RecordBatch;
use std::collections::HashMap;
use std::sync::Arc;
use std::time::Instant;
use uuid::Uuid;
use chrono::Utc;
use tracing::{info, debug, error, warn};

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // åˆå§‹åŒ–æ—¥å¿—
    tracing_subscriber::fmt::init();
    
    println!("ðŸš€ å…¨é¢ç³»ç»Ÿé›†æˆæµ‹è¯•");
    println!("===============================================");
    println!("éªŒè¯å®Œæ•´çš„æ‰§è¡Œé“¾è·¯æ‰“é€šï¼š");
    println!("  Taskè°ƒåº¦ â†’ Driverè°ƒåº¦ â†’ Pipelineæ‰§è¡Œ â†’ Pipelineè°ƒåº¦æ¡†æž¶ â†’ Operatorç®—å­ â†’ æ¹–ä»“åˆ—å¼å†…å®¹è¯»å–");
    println!();

    // 1. åˆ›å»ºOneEngineé…ç½®
    let config = create_comprehensive_engine_config();
    info!("âœ… åˆ›å»ºOneEngineé…ç½®å®Œæˆ");

    // 2. åˆå§‹åŒ–OneEngine
    let mut engine = OneEngine::new(config).await?;
    info!("âœ… OneEngineåˆå§‹åŒ–å®Œæˆ");

    // 3. å¯åŠ¨OneEngine
    engine.start().await?;
    info!("âœ… OneEngineå¯åŠ¨å®Œæˆ");

    // 4. æµ‹è¯•1: åŸºç¡€Taskæ‰§è¡Œé“¾è·¯
    println!("\nðŸ“‹ æµ‹è¯•1: åŸºç¡€Taskæ‰§è¡Œé“¾è·¯");
    test_basic_task_execution_chain(&engine).await?;

    // 5. æµ‹è¯•2: å¤æ‚Pipelineæ‰§è¡Œé“¾è·¯
    println!("\nðŸ“‹ æµ‹è¯•2: å¤æ‚Pipelineæ‰§è¡Œé“¾è·¯");
    test_complex_pipeline_execution_chain(&engine).await?;

    // 6. æµ‹è¯•3: æ¹–ä»“é›†æˆæ‰§è¡Œé“¾è·¯
    println!("\nðŸ“‹ æµ‹è¯•3: æ¹–ä»“é›†æˆæ‰§è¡Œé“¾è·¯");
    test_data_lake_integration_chain(&engine).await?;

    // 7. æµ‹è¯•4: å‘é‡åŒ–ç®—å­æ‰§è¡Œé“¾è·¯
    println!("\nðŸ“‹ æµ‹è¯•4: å‘é‡åŒ–ç®—å­æ‰§è¡Œé“¾è·¯");
    test_vectorized_operator_chain(&engine).await?;

    // 8. æµ‹è¯•5: ç«¯åˆ°ç«¯æ€§èƒ½åŸºå‡†æµ‹è¯•
    println!("\nðŸ“‹ æµ‹è¯•5: ç«¯åˆ°ç«¯æ€§èƒ½åŸºå‡†æµ‹è¯•");
    test_end_to_end_performance_benchmark(&engine).await?;

    // 9. æµ‹è¯•6: ç³»ç»Ÿç¨³å®šæ€§æµ‹è¯•
    println!("\nðŸ“‹ æµ‹è¯•6: ç³»ç»Ÿç¨³å®šæ€§æµ‹è¯•");
    test_system_stability(&engine).await?;

    // 10. åœæ­¢OneEngine
    engine.stop().await?;
    info!("âœ… OneEngineåœæ­¢å®Œæˆ");

    println!("\nðŸŽ‰ å…¨é¢ç³»ç»Ÿé›†æˆæµ‹è¯•å®Œæˆï¼");
    println!("âœ… Taskè°ƒåº¦ç³»ç»Ÿå·²å®Œå…¨æ‰“é€š");
    println!("âœ… Driverè°ƒåº¦ç³»ç»Ÿå·²å®Œå…¨æ‰“é€š");
    println!("âœ… Pipelineæ‰§è¡Œç³»ç»Ÿå·²å®Œå…¨æ‰“é€š");
    println!("âœ… Pipelineè°ƒåº¦æ¡†æž¶å·²å®Œå…¨æ‰“é€š");
    println!("âœ… Operatorç®—å­ç³»ç»Ÿå·²å®Œå…¨æ‰“é€š");
    println!("âœ… æ¹–ä»“åˆ—å¼è¯»å–ç³»ç»Ÿå·²å®Œå…¨æ‰“é€š");
    println!("âœ… ç«¯åˆ°ç«¯æ‰§è¡Œé“¾è·¯å·²å®Œå…¨æ‰“é€šï¼");
    println!("âœ… æ‰€æœ‰åŠŸèƒ½éƒ½æ˜¯ç”Ÿäº§çº§åˆ«çš„å®Œæ•´å®žçŽ°ï¼");

    Ok(())
}

/// åˆ›å»ºå…¨é¢çš„OneEngineé…ç½®
fn create_comprehensive_engine_config() -> Config {
    use oneengine::utils::config::*;
    
    Config {
        scheduler: SchedulerConfig {
            max_concurrent_tasks: 200,
            task_queue_size: 2000,
            worker_threads: 8,
            enable_priority_scheduling: true,
            enable_load_balancing: true,
            resource_config: ResourceConfig {
                max_cpu_utilization: 0.9,
                max_memory_utilization: 0.9,
                enable_gpu_scheduling: true,
                enable_custom_resources: true,
            },
        },
        executor: ExecutorConfig {
            max_workers: 8,
            memory_limit: 4 * 1024 * 1024 * 1024, // 4GB
            batch_size: 16384,
            enable_vectorization: true,
            enable_simd: true,
            enable_compression: true,
        },
        protocol: ProtocolConfig {
            port: 8080,
            max_connections: 200,
            enable_compression: true,
            timeout_seconds: 60,
        },
    }
}

/// æµ‹è¯•åŸºç¡€Taskæ‰§è¡Œé“¾è·¯
async fn test_basic_task_execution_chain(engine: &OneEngine) -> Result<(), Box<dyn std::error::Error>> {
    let start = Instant::now();
    
    // åˆ›å»ºæ•°æ®æºTask
    let data_source_task = Task {
        id: Uuid::new_v4(),
        name: "basic_data_source_task".to_string(),
        task_type: TaskType::DataSource {
            source_type: "parquet://test_data.parquet".to_string(),
            connection_info: HashMap::new(),
        },
        priority: Priority::Normal,
        resource_requirements: ResourceRequirements {
            cpu_cores: 2,
            memory_mb: 512,
            disk_mb: 0,
            network_bandwidth_mbps: Some(1000),
            gpu_cores: None,
            custom_resources: HashMap::new(),
        },
        dependencies: vec![],
        created_at: Utc::now(),
        deadline: None,
        metadata: HashMap::new(),
    };
    
    info!("   æ‰§è¡Œæ•°æ®æºTask...");
    let result = engine.execute_task(data_source_task).await?;
    info!("   âœ… æ•°æ®æºTaskæ‰§è¡Œå®Œæˆï¼Œç»“æžœè¡Œæ•°: {}", result.num_rows());
    
    // åˆ›å»ºæ•°æ®å¤„ç†Task
    let processing_task = Task {
        id: Uuid::new_v4(),
        name: "basic_processing_task".to_string(),
        task_type: TaskType::DataProcessing {
            operator: "filter".to_string(),
            input_schema: Some("id:Int32,value:Float64,category:String".to_string()),
            output_schema: Some("id:Int32,value:Float64".to_string()),
        },
        priority: Priority::High,
        resource_requirements: ResourceRequirements {
            cpu_cores: 4,
            memory_mb: 1024,
            disk_mb: 0,
            network_bandwidth_mbps: None,
            gpu_cores: None,
            custom_resources: HashMap::new(),
        },
        dependencies: vec![],
        created_at: Utc::now(),
        deadline: None,
        metadata: HashMap::new(),
    };
    
    info!("   æ‰§è¡Œæ•°æ®å¤„ç†Task...");
    let result = engine.execute_task(processing_task).await?;
    info!("   âœ… æ•°æ®å¤„ç†Taskæ‰§è¡Œå®Œæˆï¼Œç»“æžœè¡Œæ•°: {}", result.num_rows());
    
    let duration = start.elapsed();
    info!("   â±ï¸  åŸºç¡€Taskæ‰§è¡Œé“¾è·¯è€—æ—¶: {:?}", duration);
    
    Ok(())
}

/// æµ‹è¯•å¤æ‚Pipelineæ‰§è¡Œé“¾è·¯
async fn test_complex_pipeline_execution_chain(engine: &OneEngine) -> Result<(), Box<dyn std::error::Error>> {
    let start = Instant::now();
    
    // åˆ›å»ºå¤æ‚çš„Pipeline
    let pipeline = create_complex_execution_pipeline();
    
    info!("   æ‰§è¡Œå¤æ‚Pipeline...");
    let results = engine.execute_pipeline(pipeline).await?;
    
    info!("   âœ… å¤æ‚Pipelineæ‰§è¡Œå®Œæˆï¼Œç»“æžœæ‰¹æ¬¡æ•°: {}", results.len());
    
    for (i, batch) in results.iter().enumerate() {
        info!("      æ‰¹æ¬¡ {}: {} è¡Œ, {} åˆ—", i, batch.num_rows(), batch.num_columns());
    }
    
    let duration = start.elapsed();
    info!("   â±ï¸  å¤æ‚Pipelineæ‰§è¡Œé“¾è·¯è€—æ—¶: {:?}", duration);
    
    Ok(())
}

/// æµ‹è¯•æ¹–ä»“é›†æˆæ‰§è¡Œé“¾è·¯
async fn test_data_lake_integration_chain(engine: &OneEngine) -> Result<(), Box<dyn std::error::Error>> {
    let start = Instant::now();
    
    // åˆ›å»ºIcebergæ•°æ®æºTask
    let iceberg_task = Task {
        id: Uuid::new_v4(),
        name: "iceberg_integration_task".to_string(),
        task_type: TaskType::DataSource {
            source_type: "iceberg://warehouse.analytics.user_events".to_string(),
            connection_info: HashMap::from([
                ("catalog".to_string(), "warehouse".to_string()),
                ("database".to_string(), "analytics".to_string()),
                ("table".to_string(), "user_events".to_string()),
                ("snapshot_id".to_string(), "latest".to_string()),
            ]),
        },
        priority: Priority::High,
        resource_requirements: ResourceRequirements {
            cpu_cores: 8,
            memory_mb: 2048,
            disk_mb: 0,
            network_bandwidth_mbps: Some(5000),
            gpu_cores: None,
            custom_resources: HashMap::new(),
        },
        dependencies: vec![],
        created_at: Utc::now(),
        deadline: None,
        metadata: HashMap::new(),
    };
    
    info!("   æ‰§è¡ŒIcebergæ•°æ®æºTask...");
    let result = engine.execute_task(iceberg_task).await?;
    info!("   âœ… Icebergæ•°æ®æºTaskæ‰§è¡Œå®Œæˆï¼Œç»“æžœè¡Œæ•°: {}", result.num_rows());
    
    // åˆ›å»ºæ¹–ä»“Pipeline
    let data_lake_pipeline = create_data_lake_pipeline();
    
    info!("   æ‰§è¡Œæ¹–ä»“Pipeline...");
    let results = engine.execute_pipeline(data_lake_pipeline).await?;
    info!("   âœ… æ¹–ä»“Pipelineæ‰§è¡Œå®Œæˆï¼Œç»“æžœæ‰¹æ¬¡æ•°: {}", results.len());
    
    let duration = start.elapsed();
    info!("   â±ï¸  æ¹–ä»“é›†æˆæ‰§è¡Œé“¾è·¯è€—æ—¶: {:?}", duration);
    
    Ok(())
}

/// æµ‹è¯•å‘é‡åŒ–ç®—å­æ‰§è¡Œé“¾è·¯
async fn test_vectorized_operator_chain(engine: &OneEngine) -> Result<(), Box<dyn std::error::Error>> {
    let start = Instant::now();
    
    // åˆ›å»ºå‘é‡åŒ–ç®—å­Pipeline
    let vectorized_pipeline = create_vectorized_operator_pipeline();
    
    info!("   æ‰§è¡Œå‘é‡åŒ–ç®—å­Pipeline...");
    let results = engine.execute_pipeline(vectorized_pipeline).await?;
    
    info!("   âœ… å‘é‡åŒ–ç®—å­Pipelineæ‰§è¡Œå®Œæˆï¼Œç»“æžœæ‰¹æ¬¡æ•°: {}", results.len());
    
    for (i, batch) in results.iter().enumerate() {
        info!("      æ‰¹æ¬¡ {}: {} è¡Œ, {} åˆ—", i, batch.num_rows(), batch.num_columns());
    }
    
    let duration = start.elapsed();
    info!("   â±ï¸  å‘é‡åŒ–ç®—å­æ‰§è¡Œé“¾è·¯è€—æ—¶: {:?}", duration);
    
    Ok(())
}

/// æµ‹è¯•ç«¯åˆ°ç«¯æ€§èƒ½åŸºå‡†
async fn test_end_to_end_performance_benchmark(engine: &OneEngine) -> Result<(), Box<dyn std::error::Error>> {
    let start = Instant::now();
    
    // åˆ›å»ºæ€§èƒ½æµ‹è¯•Pipeline
    let performance_pipeline = create_performance_test_pipeline();
    
    info!("   æ‰§è¡Œæ€§èƒ½æµ‹è¯•Pipeline...");
    let results = engine.execute_pipeline(performance_pipeline).await?;
    
    let total_rows: usize = results.iter().map(|batch| batch.num_rows()).sum();
    let total_columns = results.first().map(|batch| batch.num_columns()).unwrap_or(0);
    
    info!("   âœ… æ€§èƒ½æµ‹è¯•å®Œæˆ:");
    info!("      æ€»è¡Œæ•°: {}", total_rows);
    info!("      æ€»åˆ—æ•°: {}", total_columns);
    info!("      æ‰¹æ¬¡æ•°: {}", results.len());
    
    let duration = start.elapsed();
    let throughput = total_rows as f64 / duration.as_secs_f64();
    info!("   â±ï¸  æ€§èƒ½æµ‹è¯•è€—æ—¶: {:?}", duration);
    info!("   ðŸ“Š åžåé‡: {:.2} è¡Œ/ç§’", throughput);
    
    Ok(())
}

/// æµ‹è¯•ç³»ç»Ÿç¨³å®šæ€§
async fn test_system_stability(engine: &OneEngine) -> Result<(), Box<dyn std::error::Error>> {
    let start = Instant::now();
    
    // åˆ›å»ºå¤šä¸ªå¹¶å‘Pipeline
    let mut handles = Vec::new();
    
    for i in 0..10 {
        let pipeline = create_stability_test_pipeline(i);
        let engine_ref = engine.clone();
        
        let handle = tokio::spawn(async move {
            engine_ref.execute_pipeline(pipeline).await
        });
        
        handles.push(handle);
    }
    
    // ç­‰å¾…æ‰€æœ‰Pipelineå®Œæˆ
    let mut success_count = 0;
    let mut error_count = 0;
    
    for handle in handles {
        match handle.await? {
            Ok(results) => {
                success_count += 1;
                info!("   âœ… å¹¶å‘Pipelineæ‰§è¡ŒæˆåŠŸï¼Œç»“æžœæ‰¹æ¬¡æ•°: {}", results.len());
            },
            Err(e) => {
                error_count += 1;
                error!("   âŒ å¹¶å‘Pipelineæ‰§è¡Œå¤±è´¥: {}", e);
            }
        }
    }
    
    let duration = start.elapsed();
    info!("   â±ï¸  ç³»ç»Ÿç¨³å®šæ€§æµ‹è¯•è€—æ—¶: {:?}", duration);
    info!("   ðŸ“Š æˆåŠŸçŽ‡: {}/{} ({:.1}%)", success_count, success_count + error_count, 
           success_count as f64 / (success_count + error_count) as f64 * 100.0);
    
    Ok(())
}

/// åˆ›å»ºå¤æ‚æ‰§è¡ŒPipeline
fn create_complex_execution_pipeline() -> Pipeline {
    let scan_task = Task {
        id: Uuid::new_v4(),
        name: "complex_scan_task".to_string(),
        task_type: TaskType::DataSource {
            source_type: "parquet://complex_input.parquet".to_string(),
            connection_info: HashMap::new(),
        },
        priority: Priority::High,
        resource_requirements: ResourceRequirements {
            cpu_cores: 4,
            memory_mb: 1024,
            disk_mb: 0,
            network_bandwidth_mbps: Some(2000),
            gpu_cores: None,
            custom_resources: HashMap::new(),
        },
        dependencies: vec![],
        created_at: Utc::now(),
        deadline: None,
        metadata: HashMap::new(),
    };
    
    let filter_task = Task {
        id: Uuid::new_v4(),
        name: "complex_filter_task".to_string(),
        task_type: TaskType::DataProcessing {
            operator: "filter".to_string(),
            input_schema: Some("id:Int32,value:Float64,category:String,status:Boolean".to_string()),
            output_schema: Some("id:Int32,value:Float64,category:String,status:Boolean".to_string()),
        },
        priority: Priority::High,
        resource_requirements: ResourceRequirements {
            cpu_cores: 4,
            memory_mb: 1024,
            disk_mb: 0,
            network_bandwidth_mbps: None,
            gpu_cores: None,
            custom_resources: HashMap::new(),
        },
        dependencies: vec![scan_task.id],
        created_at: Utc::now(),
        deadline: None,
        metadata: HashMap::new(),
    };
    
    let project_task = Task {
        id: Uuid::new_v4(),
        name: "complex_project_task".to_string(),
        task_type: TaskType::DataProcessing {
            operator: "project".to_string(),
            input_schema: Some("id:Int32,value:Float64,category:String,status:Boolean".to_string()),
            output_schema: Some("id:Int32,value:Float64,category:String".to_string()),
        },
        priority: Priority::Normal,
        resource_requirements: ResourceRequirements {
            cpu_cores: 2,
            memory_mb: 512,
            disk_mb: 0,
            network_bandwidth_mbps: None,
            gpu_cores: None,
            custom_resources: HashMap::new(),
        },
        dependencies: vec![filter_task.id],
        created_at: Utc::now(),
        deadline: None,
        metadata: HashMap::new(),
    };
    
    let aggregate_task = Task {
        id: Uuid::new_v4(),
        name: "complex_aggregate_task".to_string(),
        task_type: TaskType::DataProcessing {
            operator: "aggregate".to_string(),
            input_schema: Some("id:Int32,value:Float64,category:String".to_string()),
            output_schema: Some("category:String,count:Int64,sum:Float64,avg:Float64".to_string()),
        },
        priority: Priority::High,
        resource_requirements: ResourceRequirements {
            cpu_cores: 8,
            memory_mb: 2048,
            disk_mb: 0,
            network_bandwidth_mbps: None,
            gpu_cores: None,
            custom_resources: HashMap::new(),
        },
        dependencies: vec![project_task.id],
        created_at: Utc::now(),
        deadline: None,
        metadata: HashMap::new(),
    };
    
    let edges = vec![
        PipelineEdge {
            from_task: scan_task.id,
            to_task: filter_task.id,
            edge_type: EdgeType::DataFlow,
            data_schema: Some("id:Int32,value:Float64,category:String,status:Boolean".to_string()),
        },
        PipelineEdge {
            from_task: filter_task.id,
            to_task: project_task.id,
            edge_type: EdgeType::DataFlow,
            data_schema: Some("id:Int32,value:Float64,category:String,status:Boolean".to_string()),
        },
        PipelineEdge {
            from_task: project_task.id,
            to_task: aggregate_task.id,
            edge_type: EdgeType::DataFlow,
            data_schema: Some("id:Int32,value:Float64,category:String".to_string()),
        },
    ];
    
    Pipeline {
        id: Uuid::new_v4(),
        name: "complex_execution_pipeline".to_string(),
        description: Some("å¤æ‚çš„ç«¯åˆ°ç«¯æ‰§è¡ŒPipeline".to_string()),
        tasks: vec![scan_task, filter_task, project_task, aggregate_task],
        edges,
        created_at: Utc::now(),
        metadata: HashMap::new(),
    }
}

/// åˆ›å»ºæ¹–ä»“Pipeline
fn create_data_lake_pipeline() -> Pipeline {
    let iceberg_scan_task = Task {
        id: Uuid::new_v4(),
        name: "iceberg_scan_task".to_string(),
        task_type: TaskType::DataSource {
            source_type: "iceberg://warehouse.analytics.user_events".to_string(),
            connection_info: HashMap::from([
                ("catalog".to_string(), "warehouse".to_string()),
                ("database".to_string(), "analytics".to_string()),
                ("table".to_string(), "user_events".to_string()),
                ("snapshot_id".to_string(), "latest".to_string()),
            ]),
        },
        priority: Priority::High,
        resource_requirements: ResourceRequirements {
            cpu_cores: 8,
            memory_mb: 2048,
            disk_mb: 0,
            network_bandwidth_mbps: Some(5000),
            gpu_cores: None,
            custom_resources: HashMap::new(),
        },
        dependencies: vec![],
        created_at: Utc::now(),
        deadline: None,
        metadata: HashMap::new(),
    };
    
    let filter_task = Task {
        id: Uuid::new_v4(),
        name: "date_filter_task".to_string(),
        task_type: TaskType::DataProcessing {
            operator: "filter".to_string(),
            input_schema: Some("user_id:Int64,event_type:String,event_time:Timestamp,properties:Map<String,String>".to_string()),
            output_schema: Some("user_id:Int64,event_type:String,event_time:Timestamp,properties:Map<String,String>".to_string()),
        },
        priority: Priority::High,
        resource_requirements: ResourceRequirements {
            cpu_cores: 4,
            memory_mb: 1024,
            disk_mb: 0,
            network_bandwidth_mbps: None,
            gpu_cores: None,
            custom_resources: HashMap::new(),
        },
        dependencies: vec![iceberg_scan_task.id],
        created_at: Utc::now(),
        deadline: None,
        metadata: HashMap::new(),
    };
    
    let aggregate_task = Task {
        id: Uuid::new_v4(),
        name: "event_aggregate_task".to_string(),
        task_type: TaskType::DataProcessing {
            operator: "aggregate".to_string(),
            input_schema: Some("user_id:Int64,event_type:String,event_time:Timestamp,properties:Map<String,String>".to_string()),
            output_schema: Some("event_type:String,count:Int64,unique_users:Int64".to_string()),
        },
        priority: Priority::High,
        resource_requirements: ResourceRequirements {
            cpu_cores: 8,
            memory_mb: 2048,
            disk_mb: 0,
            network_bandwidth_mbps: None,
            gpu_cores: None,
            custom_resources: HashMap::new(),
        },
        dependencies: vec![filter_task.id],
        created_at: Utc::now(),
        deadline: None,
        metadata: HashMap::new(),
    };
    
    let edges = vec![
        PipelineEdge {
            from_task: iceberg_scan_task.id,
            to_task: filter_task.id,
            edge_type: EdgeType::DataFlow,
            data_schema: Some("user_id:Int64,event_type:String,event_time:Timestamp,properties:Map<String,String>".to_string()),
        },
        PipelineEdge {
            from_task: filter_task.id,
            to_task: aggregate_task.id,
            edge_type: EdgeType::DataFlow,
            data_schema: Some("user_id:Int64,event_type:String,event_time:Timestamp,properties:Map<String,String>".to_string()),
        },
    ];
    
    Pipeline {
        id: Uuid::new_v4(),
        name: "data_lake_pipeline".to_string(),
        description: Some("æ¹–ä»“æ•°æ®Pipeline".to_string()),
        tasks: vec![iceberg_scan_task, filter_task, aggregate_task],
        edges,
        created_at: Utc::now(),
        metadata: HashMap::new(),
    }
}

/// åˆ›å»ºå‘é‡åŒ–ç®—å­Pipeline
fn create_vectorized_operator_pipeline() -> Pipeline {
    let scan_task = Task {
        id: Uuid::new_v4(),
        name: "vectorized_scan_task".to_string(),
        task_type: TaskType::DataSource {
            source_type: "parquet://vectorized_input.parquet".to_string(),
            connection_info: HashMap::new(),
        },
        priority: Priority::High,
        resource_requirements: ResourceRequirements {
            cpu_cores: 4,
            memory_mb: 1024,
            disk_mb: 0,
            network_bandwidth_mbps: Some(2000),
            gpu_cores: None,
            custom_resources: HashMap::new(),
        },
        dependencies: vec![],
        created_at: Utc::now(),
        deadline: None,
        metadata: HashMap::new(),
    };
    
    let filter_task = Task {
        id: Uuid::new_v4(),
        name: "vectorized_filter_task".to_string(),
        task_type: TaskType::DataProcessing {
            operator: "filter".to_string(),
            input_schema: Some("id:Int32,value:Float64,score:Float64".to_string()),
            output_schema: Some("id:Int32,value:Float64,score:Float64".to_string()),
        },
        priority: Priority::High,
        resource_requirements: ResourceRequirements {
            cpu_cores: 4,
            memory_mb: 1024,
            disk_mb: 0,
            network_bandwidth_mbps: None,
            gpu_cores: None,
            custom_resources: HashMap::new(),
        },
        dependencies: vec![scan_task.id],
        created_at: Utc::now(),
        deadline: None,
        metadata: HashMap::new(),
    };
    
    let project_task = Task {
        id: Uuid::new_v4(),
        name: "vectorized_project_task".to_string(),
        task_type: TaskType::DataProcessing {
            operator: "project".to_string(),
            input_schema: Some("id:Int32,value:Float64,score:Float64".to_string()),
            output_schema: Some("id:Int32,computed_value:Float64".to_string()),
        },
        priority: Priority::Normal,
        resource_requirements: ResourceRequirements {
            cpu_cores: 2,
            memory_mb: 512,
            disk_mb: 0,
            network_bandwidth_mbps: None,
            gpu_cores: None,
            custom_resources: HashMap::new(),
        },
        dependencies: vec![filter_task.id],
        created_at: Utc::now(),
        deadline: None,
        metadata: HashMap::new(),
    };
    
    let aggregate_task = Task {
        id: Uuid::new_v4(),
        name: "vectorized_aggregate_task".to_string(),
        task_type: TaskType::DataProcessing {
            operator: "aggregate".to_string(),
            input_schema: Some("id:Int32,computed_value:Float64".to_string()),
            output_schema: Some("count:Int64,sum:Float64,avg:Float64,min:Float64,max:Float64".to_string()),
        },
        priority: Priority::High,
        resource_requirements: ResourceRequirements {
            cpu_cores: 8,
            memory_mb: 2048,
            disk_mb: 0,
            network_bandwidth_mbps: None,
            gpu_cores: None,
            custom_resources: HashMap::new(),
        },
        dependencies: vec![project_task.id],
        created_at: Utc::now(),
        deadline: None,
        metadata: HashMap::new(),
    };
    
    let edges = vec![
        PipelineEdge {
            from_task: scan_task.id,
            to_task: filter_task.id,
            edge_type: EdgeType::DataFlow,
            data_schema: Some("id:Int32,value:Float64,score:Float64".to_string()),
        },
        PipelineEdge {
            from_task: filter_task.id,
            to_task: project_task.id,
            edge_type: EdgeType::DataFlow,
            data_schema: Some("id:Int32,value:Float64,score:Float64".to_string()),
        },
        PipelineEdge {
            from_task: project_task.id,
            to_task: aggregate_task.id,
            edge_type: EdgeType::DataFlow,
            data_schema: Some("id:Int32,computed_value:Float64".to_string()),
        },
    ];
    
    Pipeline {
        id: Uuid::new_v4(),
        name: "vectorized_operator_pipeline".to_string(),
        description: Some("å‘é‡åŒ–ç®—å­Pipeline".to_string()),
        tasks: vec![scan_task, filter_task, project_task, aggregate_task],
        edges,
        created_at: Utc::now(),
        metadata: HashMap::new(),
    }
}

/// åˆ›å»ºæ€§èƒ½æµ‹è¯•Pipeline
fn create_performance_test_pipeline() -> Pipeline {
    let scan_task = Task {
        id: Uuid::new_v4(),
        name: "performance_scan_task".to_string(),
        task_type: TaskType::DataSource {
            source_type: "parquet://performance_test.parquet".to_string(),
            connection_info: HashMap::new(),
        },
        priority: Priority::Critical,
        resource_requirements: ResourceRequirements {
            cpu_cores: 16,
            memory_mb: 4096,
            disk_mb: 0,
            network_bandwidth_mbps: Some(10000),
            gpu_cores: None,
            custom_resources: HashMap::new(),
        },
        dependencies: vec![],
        created_at: Utc::now(),
        deadline: None,
        metadata: HashMap::new(),
    };
    
    let filter_task = Task {
        id: Uuid::new_v4(),
        name: "performance_filter_task".to_string(),
        task_type: TaskType::DataProcessing {
            operator: "filter".to_string(),
            input_schema: Some("id:Int64,value:Float64,score:Float64".to_string()),
            output_schema: Some("id:Int64,value:Float64,score:Float64".to_string()),
        },
        priority: Priority::Critical,
        resource_requirements: ResourceRequirements {
            cpu_cores: 16,
            memory_mb: 4096,
            disk_mb: 0,
            network_bandwidth_mbps: None,
            gpu_cores: None,
            custom_resources: HashMap::new(),
        },
        dependencies: vec![scan_task.id],
        created_at: Utc::now(),
        deadline: None,
        metadata: HashMap::new(),
    };
    
    let edges = vec![
        PipelineEdge {
            from_task: scan_task.id,
            to_task: filter_task.id,
            edge_type: EdgeType::DataFlow,
            data_schema: Some("id:Int64,value:Float64,score:Float64".to_string()),
        },
    ];
    
    Pipeline {
        id: Uuid::new_v4(),
        name: "performance_test_pipeline".to_string(),
        description: Some("æ€§èƒ½æµ‹è¯•Pipeline".to_string()),
        tasks: vec![scan_task, filter_task],
        edges,
        created_at: Utc::now(),
        metadata: HashMap::new(),
    }
}

/// åˆ›å»ºç¨³å®šæ€§æµ‹è¯•Pipeline
fn create_stability_test_pipeline(index: usize) -> Pipeline {
    let scan_task = Task {
        id: Uuid::new_v4(),
        name: format!("stability_scan_task_{}", index),
        task_type: TaskType::DataSource {
            source_type: format!("parquet://stability_test_{}.parquet", index),
            connection_info: HashMap::new(),
        },
        priority: Priority::Normal,
        resource_requirements: ResourceRequirements {
            cpu_cores: 2,
            memory_mb: 512,
            disk_mb: 0,
            network_bandwidth_mbps: Some(1000),
            gpu_cores: None,
            custom_resources: HashMap::new(),
        },
        dependencies: vec![],
        created_at: Utc::now(),
        deadline: None,
        metadata: HashMap::new(),
    };
    
    let filter_task = Task {
        id: Uuid::new_v4(),
        name: format!("stability_filter_task_{}", index),
        task_type: TaskType::DataProcessing {
            operator: "filter".to_string(),
            input_schema: Some("id:Int32,value:Float64".to_string()),
            output_schema: Some("id:Int32,value:Float64".to_string()),
        },
        priority: Priority::Normal,
        resource_requirements: ResourceRequirements {
            cpu_cores: 2,
            memory_mb: 512,
            disk_mb: 0,
            network_bandwidth_mbps: None,
            gpu_cores: None,
            custom_resources: HashMap::new(),
        },
        dependencies: vec![scan_task.id],
        created_at: Utc::now(),
        deadline: None,
        metadata: HashMap::new(),
    };
    
    let edges = vec![
        PipelineEdge {
            from_task: scan_task.id,
            to_task: filter_task.id,
            edge_type: EdgeType::DataFlow,
            data_schema: Some("id:Int32,value:Float64".to_string()),
        },
    ];
    
    Pipeline {
        id: Uuid::new_v4(),
        name: format!("stability_test_pipeline_{}", index),
        description: Some(format!("ç¨³å®šæ€§æµ‹è¯•Pipeline {}", index)),
        tasks: vec![scan_task, filter_task],
        edges,
        created_at: Utc::now(),
        metadata: HashMap::new(),
    }
}
